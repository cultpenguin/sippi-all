function [net,tr,mfunc]=neural_network_learn(x, t,mfunc,hiddenLayerSize,trainParam,useGPU)
% Solve an Input-Output Fitting problem with a Neural Network
%m% Script generated by Neural Fitting %
% Created 15-Sep-2016 21:03:17
%
% This script assumes these variables are defined:
%
%   x - input data (model parameters).
%   t - target data.
%
%  mfunc [string] name of m-file to generate
%
%x = ATTS;
%t = DATA;



if nargin<4
    hiddenLayerSize = 10;
end    
if nargin<5
    trainParam.null=[];
end    
if nargin<6;
    useGPU = 0;
end    

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
if useGPU==1
    trainFcn='trainscg';
else
    % trainFcn = 'trainlm'; % Levenberg-Marquardt backpropagation. % SLOW FOR BIG DATA SETS / MEMORY DEMANDING
    % trainFcn = 'trainbr';  % BAYESIAN REGULARIZATION
    trainFcn='trainscg';
end

% Create a Fitting Network
% = 10;
%net = fitnet([5 5],trainFcn);
net = fitnet([hiddenLayerSize],trainFcn);

% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.input.processFcns = {'removeconstantrows','mapminmax'};
net.output.processFcns = {'removeconstantrows','mapminmax'};

% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivide
net.divideFcn = 'dividerand';  % Divide data randomly
net.divideMode = 'sample';  % Divide up every sample
net.divideParam.trainRatio = 70/100;
net.divideParam.valRatio = 15/100;
net.divideParam.testRatio = 15/100;

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'mse';  % Mean Squared Error
%net.performFcn = 'mae';  % Mean Abslute Error

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotregression', 'plotfit'};


% train parameters
net.trainParam.showWindow=1;
net.trainParam.epochs=10000;
net.trainParam.goal=.000002;
net.trainParam.max_fail=30;
net.trainParam.min_grad=1e-6;

%% update trainParams
fn=fieldnames(trainParam);
for i=1:length(fn)
    if isfield(net.trainParam,fn{i});
        net.trainParam.(fn{i})=trainParam.(fn{i});
    end
end
%%
% set function_name
if nargin<3
    mfunc=sprintf('myNN_N%d_M%d_NR%d_HL%d',size(x,1),size(t,1),size(x,2),hiddenLayerSize);
end


%useGPU=1;
%if prod(size(x))>10e+7
%    useGPU=0;
%end
% Train the Network
if useGPU==1
    % GPU
    [net,tr] = train(net,x,t,'useGPU','yes','showResources','yes');
else
    % CPU   
    [net,tr] = train(net,x,t,'useParallel','no','showResources','yes');
    % [net,tr] = train(net,x,t,'useParallel','yes','showResources','yes');
end

try
%    nntraintool('close');
end
% Test the Network
y = net(x);
e = gsubtract(t,y);
performance = perform(net,t,y);

disp(sprintf('%s: var(delta_t)=%4.2f',mfilename,performance));

% Recalculate Training, Validation and Test Performance
trainTargets = t .* tr.trainMask{1};
valTargets = t .* tr.valMask{1};
testTargets = t .* tr.testMask{1};
trainPerformance = perform(net,trainTargets,y);
valPerformance = perform(net,valTargets,y);
testPerformance = perform(net,testTargets,y);

disp(sprintf('%s: TRAIN MSE(delta_t)=%4.2f',mfilename,trainPerformance));
disp(sprintf('%s: VAL   MSE(delta_t)=%4.2f',mfilename,valPerformance));
disp(sprintf('%s: TEST  MSE(delta_t)=%4.2f',mfilename,testPerformance));



% View the Network
%view(net)

% Plots
% Uncomment these lines to enable various plots.
figure(11); plotperform(tr);
%figure, plottrainstate(tr)
%figure, ploterrhist(e)
%figure, plotregression(t,y)
%figure, plotfit(net,x,t)

% Deployment
% Change the (false) values to (true) to enable the following code blocks.
% See the help for each generation function for more information.

if (false)
    % Generate MATLAB function for neural network for application
    % deployment in MATLAB scripts or with MATLAB Compiler and Builder
    % tools, or simply to examine the calculations your trained neural
    % network performs.
    genFunction(net,mfunc);
    y = feval(mfunc,x);
end
if (true)
    % Generate a matrix-only MATLAB function for neural network code
    % generation with MATLAB Coder tools.
    genFunction(net,mfunc,'MatrixOnly','yes');
    y = feval(mfunc,x);
end
if (false)
    % Generate a Simulink diagram for simulation or deployment with.
    % Simulink Coder tools.
    gensim(net);
end
